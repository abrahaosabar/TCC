{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f0f3fd-7e9b-4b24-af67-ea3d41de9015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba056810",
   "metadata": {},
   "source": [
    "# First Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a903db-3bda-4978-a910-3e956ffca594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affed56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e127b84a",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "605fec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data\"\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=DATA_PATH,\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=DATA_PATH,\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd740286",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aae3e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66e8687",
   "metadata": {},
   "source": [
    "## MNIST Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dde7edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "total_steps = len(train_dataloader)\n",
    "print(total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a28533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c422bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self,input_size:int=28*28):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(input_size,input_size//2)\n",
    "        self.fc2 = nn.Linear(input_size//2,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e36e170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch(model:nn.Module,optimizer,criterion):\n",
    "    running_loss = 0.0\n",
    "    for images,labels in train_dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Running Loss: {running_loss/total_steps:.3f}\")\n",
    "    return model\n",
    "\n",
    "def train_model(model,optimizer,criterion,epochs,save_file,continue_training=False):\n",
    "    save_file = Path(save_file)\n",
    "    is_model_available = save_file.is_file()\n",
    "    if is_model_available:\n",
    "        model.load_state_dict(torch.load(save_file))\n",
    "    if is_model_available and not continue_training:\n",
    "        return model\n",
    "    for epoch in range(epochs):\n",
    "        model = one_epoch(model,optimizer,criterion)\n",
    "        print(f\"Epoch {epoch} finished.\")\n",
    "    torch.save(model.state_dict(),save_file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248043a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f9d766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    ")\n",
    "model = train_model(model=model,optimizer=optimizer,criterion=criterion,epochs=20,save_file=\"./mnist_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "953b6bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy():\n",
    "    correct = 0\n",
    "    total = len(test_dataloader.dataset)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs,1)\n",
    "            correct += (predicted==labels).sum().item()\n",
    "    return correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "620cfea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75fa44e",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c57e9444",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self,input:int=28*28):\n",
    "        super().__init__()\n",
    "        # self.flatten = nn.Flatten\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,36),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(36,18),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(18,9)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(9, 18),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(18, 36),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(36, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,input),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        # x = self.flatten(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c9f167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder().to(device)\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-1,weight_decay = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21b73089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_epoch(model,loss,optimizer):\n",
    "    running_loss = 0.0\n",
    "    for images,_ in train_dataloader:\n",
    "        images = images.reshape(-1,28*28)\n",
    "        \n",
    "        images = images.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,images)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss+=loss.item()\n",
    "    print(f\"Running Loss: {running_loss/total_steps:.3f}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_autoencoder(model,loss,optimizer, save_file, epochs=EPOCHS,continue_training=False):\n",
    "    save_file = Path(save_file)\n",
    "    if save_file.is_file():\n",
    "        model.load_state_dict(torch.load(save_file))\n",
    "    if save_file.is_file() and not continue_training:\n",
    "        return model\n",
    "    for epoch in range(epochs):\n",
    "        model = autoencoder_epoch(model=model,loss=loss,optimizer=optimizer)\n",
    "        print(f\"Finished epoch {epoch+1}.\")\n",
    "    torch.save(model.state_dict(),save_file)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "201ebe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Loss: 639.078\n",
      "Finished epoch 1.\n",
      "Running Loss: 639.039\n",
      "Finished epoch 2.\n",
      "Running Loss: 639.111\n",
      "Finished epoch 3.\n",
      "Running Loss: 639.306\n",
      "Finished epoch 4.\n",
      "Running Loss: 639.965\n",
      "Finished epoch 5.\n",
      "Running Loss: 639.960\n",
      "Finished epoch 6.\n",
      "Running Loss: 639.960\n",
      "Finished epoch 7.\n",
      "Running Loss: 640.640\n",
      "Finished epoch 8.\n",
      "Running Loss: 641.096\n",
      "Finished epoch 9.\n",
      "Running Loss: 641.218\n",
      "Finished epoch 10.\n",
      "Running Loss: 641.062\n",
      "Finished epoch 11.\n",
      "Running Loss: 640.635\n",
      "Finished epoch 12.\n",
      "Running Loss: 640.586\n",
      "Finished epoch 13.\n",
      "Running Loss: 640.471\n",
      "Finished epoch 14.\n",
      "Running Loss: 640.675\n",
      "Finished epoch 15.\n",
      "Running Loss: 640.805\n",
      "Finished epoch 16.\n",
      "Running Loss: 640.831\n",
      "Finished epoch 17.\n",
      "Running Loss: 641.023\n",
      "Finished epoch 18.\n",
      "Running Loss: 641.157\n",
      "Finished epoch 19.\n",
      "Running Loss: 640.093\n",
      "Finished epoch 20.\n",
      "Running Loss: 640.397\n",
      "Finished epoch 21.\n",
      "Running Loss: 641.461\n",
      "Finished epoch 22.\n"
     ]
    }
   ],
   "source": [
    "model = train_autoencoder(model=model,loss=loss,optimizer=optimizer,epochs=50,save_file=\"./autoencoder.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0bca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for images,label in test_dataloader:\n",
    "        print(label[-1])\n",
    "        images = images.to(device)\n",
    "        images = images.reshape(-1,28*28)\n",
    "        images = model(images)\n",
    "        images = images.reshape(-1,28,28)\n",
    "        images = images.to(\"cpu\")\n",
    "        plt.imshow(images[-1])\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
